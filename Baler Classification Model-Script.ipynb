{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "import mysql.connector\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlalchemy as sa\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_con_str = 'mysql+mysqldb://mercenary:Flxi8571@40.69.142.165:3306/Sustayn'  # NST02 / PRO\n",
    "#sql_con_str = 'mysql+mysqldb://mercenary:Flxi8571@52.173.202.38:3306/Sustayn'  # NST01 / DEV\n",
    "ENGINE = sa.create_engine(sql_con_str, pool_recycle = 3600)\n",
    "\n",
    "# Stract the data from the Database\n",
    "SQL = \"\"\"\n",
    "SELECT b.*\n",
    "FROM sustayn.v_ml_baler_productor_history b\n",
    "LEFT JOIN sustayn.ml_auto_audit a ON b.id = a.id \n",
    "WHERE b.audit_date IS NULL\n",
    "AND b.ir_class IS NOT NULL\n",
    "AND a.id is null\n",
    "UNION\n",
    "SELECT DeviceType, Null, Null, max(package_date), device_id, Null, Null, Null, Null, NUll, Null, NUll, 'KG', 'A', Null, Null, Null, Null\n",
    "FROM sustayn.v_ml_baler_productor_history\n",
    "WHERE audit_date IS NOT NULL\n",
    "GROUP BY DeviceType, device_id;\n",
    "\"\"\"\n",
    "\n",
    "# read data from db to DataFrame\n",
    "df = pd.read_sql_query(SQL, ENGINE)\n",
    "#df.to_csv('data_frame_src_070120.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 18)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('data_frame_src_06292020-bk.csv', index_col=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the missing values\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert package_date to date time to order for the most recent\n",
    "df['package_date']   = df['package_date'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe by device_code and package_date\n",
    "df.sort_values(by=['device_id','package_date'], ascending=[True, True], inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index with the new order\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>id</th>\n",
       "      <th>img_url</th>\n",
       "      <th>package_date</th>\n",
       "      <th>device_id</th>\n",
       "      <th>DeviceCode</th>\n",
       "      <th>package_id</th>\n",
       "      <th>barcode</th>\n",
       "      <th>material_type</th>\n",
       "      <th>material_description_from_original</th>\n",
       "      <th>ir_original_class</th>\n",
       "      <th>net_weight</th>\n",
       "      <th>unit</th>\n",
       "      <th>audit_status</th>\n",
       "      <th>audit_date</th>\n",
       "      <th>audit_userid</th>\n",
       "      <th>ir_class</th>\n",
       "      <th>ir_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Baler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-02 11:34:57</td>\n",
       "      <td>d0e3f2d5-e865-40f4-897e-9b517bd394a6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>KG</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DeviceType  id  img_url        package_date  \\\n",
       "137      Baler   0        0 2020-07-02 11:34:57   \n",
       "\n",
       "                                device_id  DeviceCode  package_id  barcode  \\\n",
       "137  d0e3f2d5-e865-40f4-897e-9b517bd394a6           0           0        0   \n",
       "\n",
       "     material_type  material_description_from_original  ir_original_class  \\\n",
       "137              0                                   0                  0   \n",
       "\n",
       "     net_weight unit audit_status  audit_date  audit_userid  ir_class  \\\n",
       "137           0   KG            A           0             0         0   \n",
       "\n",
       "     ir_confidence  \n",
       "137              0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['device_id'] == 'd0e3f2d5-e865-40f4-897e-9b517bd394a6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create extra labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## material_description_from_original  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine MaterialDescription to group in 3 categories fewer categories\n",
    "def material_description(material):\n",
    "    \n",
    "    if 'OCC' in material:\n",
    "        return 'BALED CARDBOARD'\n",
    "    elif 'CARTON' in material:\n",
    "        return 'BALED CARDBOARD'\n",
    "    elif 'CARDBOARD' in material:\n",
    "        return 'BALED CARDBOARD'\n",
    "        \n",
    "    elif 'FILM' in material:\n",
    "        return 'BALED FILM'\n",
    "    elif 'LDP' in material:\n",
    "        return 'BALED FILM'\n",
    "    elif 'PLAYO' in material:\n",
    "        return 'BALED FILM'\n",
    "    elif material == 'PLMX':\n",
    "        return 'BALED FILM'\n",
    "    elif material == 'SHRINK WRAP':\n",
    "        return 'BALED FILM'\n",
    "    elif material == 'BOMA':\n",
    "        return 'BALED FILM'\n",
    "    \n",
    "    else:\n",
    "        return 'BALED OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['material_description_f'] = df['material_description_from_original'].astype(str).str.upper().apply(material_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BALED OTHER    177\n",
       "Name: material_description_f, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['material_description_f'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## material_description_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['material_description_prev'] = df.groupby(by=['device_id'])['material_description_f'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['material_description_prev'] = df['material_description_prev'].fillna(df['material_description_f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## material_description_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['material_description_after'] = df.groupby(by=['device_id'])['material_description_f'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['material_description_after'] = df['material_description_after'].fillna(df['material_description_f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## package_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new field from the package_date but truncating the secs\n",
    "df['package_date_f'] = df['package_date'].dt.strftime(\"%m/%d/%Y %H:%M\").astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creata a time interval delta\n",
    "def diff_func(df):\n",
    "    return abs(df.diff().dt.total_seconds() / 60)\n",
    "\n",
    "# Now call the function using .apply\n",
    "df['time_delta_f'] = df.groupby(['device_id'])['package_date'].apply(diff_func)\n",
    "\n",
    "# Fill in any NaN values\n",
    "df['time_delta_f'].fillna('0', inplace=True)\n",
    "\n",
    "# Convert the output into a float\n",
    "df['time_delta_f'] = pd.to_numeric(df['time_delta_f']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standard_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all the weights by making everything KGs\n",
    "def standard_weight(row):\n",
    "    if row['unit'] == 'LB':\n",
    "        return round(row['net_weight'] * 0.453592 , 0)\n",
    "    else:\n",
    "        return row['net_weight']\n",
    "    \n",
    "df['standard_weight_f'] = df.apply(standard_weight, axis =1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## barcode to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmedel\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "# Create an aditional field that contains if the bale has a barcode or not.\n",
    "df['barcode_f'] = np.where(df['barcode'] == 'null', 0, df['barcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_f'] = np.where(df['barcode_f'] == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## img_url to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_f'] = np.where(df['img_url'] == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['DeviceType','DeviceCode','package_id','material_type','barcode','audit_date','audit_userid'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duplicates in manual audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates are marked from zero to one\n",
    "df['audit_duplicates_f'] = df.groupby(by=['device_id'])['time_delta_f'].shift(-1, fill_value=60)\n",
    "df['audit_duplicates_f'] = np.where(df['audit_duplicates_f'] <= 10, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eliminate records audited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 21)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[df['audit_status'] == 'A'].index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distinct the group with similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audit_duplicates_groups'] = np.where(df['material_description_prev'] != df['material_description_f'], 1, df['audit_duplicates_f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_description_f</th>\n",
       "      <th>material_description_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [material_description_f, material_description_prev]\n",
       "Index: []"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['device_id'] == '461bfe45-a57f-4713-bde0-6388586f1507'][['material_description_f','material_description_prev']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_description_f</th>\n",
       "      <th>material_description_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [material_description_f, material_description_prev]\n",
       "Index: []"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['device_id'] == '9fb44f7b-c0db-495d-b99a-77850eb4d385'][['material_description_f','material_description_prev']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the duplicates_groups_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: audit_duplicates_groups, dtype: int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['audit_duplicates_groups'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>package_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material_description_from_original</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir_original_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audit_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir_confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material_description_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material_description_prev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material_description_after</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>package_date_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_delta_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard_weight_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barcode_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audit_duplicates_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audit_duplicates_groups</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_duplicates_groups</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [id, img_url, package_date, device_id, material_description_from_original, ir_original_class, net_weight, unit, audit_status, ir_class, ir_confidence, material_description_f, material_description_prev, material_description_after, package_date_f, time_delta_f, standard_weight_f, barcode_f, label_f, image_f, audit_duplicates_f, audit_duplicates_groups, count_duplicates_groups]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count_duplicates_groups'] = df.groupby(by=['device_id'])['audit_duplicates_groups'].cumcount().mask(df['audit_duplicates_groups'] == 0, 1)\n",
    "df[df['device_id'] == 'a6fe2bcc-c031-439b-a89a-604b3e979aa8'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validad the records with the Image Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[(df['ir_class'] != 'BALED EMPTY') & (df['ir_confidence'] <= 0.80) & (df['image_f'] == 1)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: audit_status_imgs, dtype: int64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['audit_status_imgs'] = np.where(df['ir_class'] != df['material_description_f'], 'R', 'A')\n",
    "df['audit_status_imgs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>package_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material_description_from_original</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir_original_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audit_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir_confidence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material_description_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material_description_prev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material_description_after</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>package_date_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_delta_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard_weight_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barcode_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audit_duplicates_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audit_duplicates_groups</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_duplicates_groups</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audit_status_imgs</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [id, img_url, package_date, device_id, material_description_from_original, ir_original_class, net_weight, unit, audit_status, ir_class, ir_confidence, material_description_f, material_description_prev, material_description_after, package_date_f, time_delta_f, standard_weight_f, barcode_f, label_f, image_f, audit_duplicates_f, audit_duplicates_groups, count_duplicates_groups, audit_status_imgs]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('baler_classifier.pkl', 'rb')\n",
    "classifier = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_src = df[['device_id',\n",
    "             'id',\n",
    "             'label_f',\n",
    "             'image_f',\n",
    "             'time_delta_f',\n",
    "             'standard_weight_f',\n",
    "             'material_description_f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>id</th>\n",
       "      <th>label_f</th>\n",
       "      <th>image_f</th>\n",
       "      <th>time_delta_f</th>\n",
       "      <th>standard_weight_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [device_id, id, label_f, image_f, time_delta_f, standard_weight_f]\n",
       "Index: []"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = pd.get_dummies(df_src,\n",
    "                          columns=[\"material_description_f\"],\n",
    "                          drop_first=False)\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>id</th>\n",
       "      <th>label_f</th>\n",
       "      <th>image_f</th>\n",
       "      <th>time_delta_f</th>\n",
       "      <th>standard_weight_f</th>\n",
       "      <th>material_description_f_BALED CARDBOARD</th>\n",
       "      <th>material_description_f_BALED FILM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [device_id, id, label_f, image_f, time_delta_f, standard_weight_f, material_description_f_BALED CARDBOARD, material_description_f_BALED FILM]\n",
       "Index: []"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df_model.drop(columns=['material_description_f_BALED OTHER'], \n",
    "              inplace=True)\n",
    "except:\n",
    "    \n",
    "    columns_list = df_.columns\n",
    "    \n",
    "    column_cardboard = 'material_description_f_BALED CARDBOARD'\n",
    "    column_film = 'material_description_f_BALED FILM'\n",
    "    \n",
    "    if column_cardboard not in columns_list:\n",
    "        df_model[column_cardboard] = 0\n",
    "    \n",
    "    if column_film not in columns_list:\n",
    "        df_model[column_film] = 0\n",
    "\n",
    "df_model.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the X and Y variables\n",
    "X = df_model[['label_f',\n",
    "              'image_f',\n",
    "              'time_delta_f',\n",
    "              'standard_weight_f',\n",
    "              'material_description_f_BALED CARDBOARD',\n",
    "              'material_description_f_BALED FILM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-187-9d7c8105e43f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'audit_status_pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    390\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    652\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 654\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "pred_y = classifier.predict(X)\n",
    "pred_y\n",
    "\n",
    "df['audit_status_pred'] = pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## audit result of the group of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates_in_groups(temp_df):\n",
    "    \n",
    "    temp_df['audit_status_group'] = np.where((temp_df['audit_status_pred'] == 'A') & (temp_df['audit_status_imgs'] == 'A'), 'A', 'R')\n",
    "    \n",
    "    if len(temp_df) == 1:\n",
    "        return temp_df\n",
    "    \n",
    "    print('---------------------- ', temp_df['device_id'].unique(), ' -- ', len(temp_df))\n",
    "    \n",
    "    group_flag = False\n",
    "    lower_pointer = 0\n",
    "    upper_pointer = 0\n",
    "    second_val = True\n",
    "\n",
    "    for i in range(len(temp_df)):\n",
    "\n",
    "        if temp_df['audit_duplicates_groups'].iloc[i] == 0:\n",
    "\n",
    "            if group_flag == False:\n",
    "                group_flag = True\n",
    "                lower_pointer = i\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if group_flag == True:\n",
    "                group_flag = False\n",
    "                upper_pointer = i\n",
    "                \n",
    "                print('lower_pointer', lower_pointer, ': upper_pointer', upper_pointer)\n",
    "                print('Number of items duplicated: ',len(temp_df[lower_pointer : upper_pointer + 1]))\n",
    "                print(temp_df[lower_pointer : upper_pointer + 1][['id',\n",
    "                                                                  'audit_status_pred',\n",
    "                                                                  'audit_status_imgs',\n",
    "                                                                  'audit_status_group',\n",
    "                                                                  'package_date_f',\n",
    "                                                                  'time_delta_f']])\n",
    "                                \n",
    "                audit_pre = list(temp_df[lower_pointer:upper_pointer+1]['audit_status_pred'])\n",
    "                audit_img = list(temp_df[lower_pointer:upper_pointer+1]['audit_status_imgs'])\n",
    "                \n",
    "                if ('A' in audit_pre) & ('A' in audit_img):\n",
    "                    \n",
    "                    print('Find the best candidate in the group of records.')\n",
    "                    \n",
    "                    # --------------------\n",
    "                    # Scenario 1: \n",
    "                    # The record masked as 'A' in the audit_pred is the best candidate\n",
    "                    # --------------------\n",
    "                    print('Trying 1 scenario...')\n",
    "                    for j in range(lower_pointer, upper_pointer + 1):\n",
    "                        if ((temp_df.iloc[j]['audit_status_pred'] == 'A') & \n",
    "                            (temp_df.iloc[j]['label_f'] == 1) & \n",
    "                            (temp_df.iloc[j]['image_f'] == 1) & \n",
    "                            (temp_df.iloc[j]['standard_weight_f'] >= 80)):\n",
    "                            \n",
    "                            print('Just accept one record... Scenario 1')\n",
    "                            temp_df.iloc[lower_pointer:upper_pointer + 1, -1] = 'D'\n",
    "                            temp_df.iloc[j, -1] = 'A'\n",
    "                            second_val = False\n",
    "                            break\n",
    "                    \n",
    "                    # --------------------\n",
    "                    # Scenario 2: \n",
    "                    # When in the audit_pred there is not a good candiate \n",
    "                    # and we need to select one from the audit_img list\n",
    "                    # --------------------\n",
    "                    if second_val == True:\n",
    "                        print('Trying 2 scenario...')\n",
    "                        for j in range(lower_pointer, upper_pointer + 1):\n",
    "                            if ((temp_df.iloc[j]['label_f'] == 1) & \n",
    "                                (temp_df.iloc[j]['image_f'] == 1) & \n",
    "                                (temp_df.iloc[j]['standard_weight_f'] >= 80)):\n",
    "\n",
    "                                print('Just accept one record... Scenario 2')\n",
    "                                temp_df.iloc[lower_pointer:upper_pointer + 1, -1] = 'D'\n",
    "                                temp_df.iloc[j, -1] = 'A'\n",
    "                                break\n",
    "                    \n",
    "                    print(temp_df[lower_pointer : upper_pointer + 1][['id',\n",
    "                                                                  'audit_status_pred',\n",
    "                                                                  'audit_status_imgs',\n",
    "                                                                  'audit_status_group',\n",
    "                                                                  'package_date_f',\n",
    "                                                                  'time_delta_f']])                      \n",
    "                else:\n",
    "                    \n",
    "                    # --------------------\n",
    "                    # Scenario 3:\n",
    "                    # If there is not any valid record from the ML model and Image Classification Model\n",
    "                    # then mask as reject all the records 'R'\n",
    "                    # --------------------\n",
    "                    print('Reject all the records...')\n",
    "                    for j in range(lower_pointer, upper_pointer + 1):\n",
    "                            temp_df.iloc[j, -1] = 'R'\n",
    "                print('**********************\\n')\n",
    "                            \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df\n",
    "#df_ = df[df['device_id'] == 'a6fe2bcc-c031-439b-a89a-604b3e979aa8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_.groupby(by=['device_id']).apply(find_duplicates_in_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_[df_['device_id'] == 'a5c55439-4443-4d89-b79c-24741f0d8cb6'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['audit_status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the records that could be 'Changed' by human validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['audit_status_valid'] = df_['audit_status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Records that could be re-audit will be mark as C\n",
    "# --------------------\n",
    "\n",
    "df_.loc[((df_['ir_class'] == 'BALED EMPTY') & \n",
    "    (df_['audit_status_group'] == 'R') & \n",
    "    (df_['audit_status_pred'] == 'A') & \n",
    "    ((df_['material_description_f'] != 'BALED OTHER'))), 'audit_status_valid'] = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Records that could be re-audit will be mark as C, second pass\n",
    "# --------------------\n",
    "\n",
    "df_.loc[((df_['ir_class'] != 'BALED EMPTY') & \n",
    "    (df_['audit_status_group'] == 'R') & \n",
    "    (df_['material_description_f'] == df_['ir_class']) & \n",
    "    (df_['material_description_f'] != df_['material_description_prev']) & \n",
    "    (df_['material_description_f'] != df_['material_description_after'])), 'audit_status_valid'] = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['audit_status_valid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['process_date'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_sql(name='ml_auto_audit', con=ENGINE, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "  host=\"52.173.202.38\",\n",
    "  user=\"mercenary\",\n",
    "  passwd=\"Flxi8571\",\n",
    "  database=\"sustayn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_audited_records(conn, audit_status, audit_userid, audit_date, audit_reject_reasonid, id_record):\n",
    "    mycursor = conn.cursor()\n",
    "    string_sql = \"UPDATE baler.device_producor_history SET audit_status = '{}', audit_userid = '{}', audit_date = '{}', audit_reject_reasonid = {} WHERE id = '{}'\".format(audit_status, audit_userid, audit_date, audit_reject_reasonid, id_record)\n",
    "    #print(string_sql)\n",
    "\n",
    "    mycursor.execute(string_sql)\n",
    "    print(mycursor.rowcount, \"record(s) affected\")\n",
    "\n",
    "    mycursor.close()\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_status = None\n",
    "audit_userid = 'AutoAI'\n",
    "audit_reason = None\n",
    "\n",
    "for i in range(len(df_)):\n",
    "    \n",
    "    process_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    audit_reason = 'null'\n",
    "    \n",
    "    if df_.iloc[i]['audit_status_valid'] == 'A':\n",
    "        audit_status = 'A'\n",
    "        \n",
    "    elif df_.iloc[i]['audit_status_valid'] == 'R':\n",
    "        \n",
    "        audit_status = 'R'\n",
    "        audit_reason = '9'\n",
    "        \n",
    "    elif df_.iloc[i]['audit_status_valid'] == 'D':\n",
    "        audit_status = 'R'\n",
    "        audit_reason = '10'\n",
    "        \n",
    "    elif df_.iloc[i]['audit_status_valid'] == 'P':\n",
    "        audit_status = 'P'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    update_audited_records(conn, audit_status, audit_userid, process_time, audit_reason, df_.iloc[i]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'a6fe2bcc-c031-439b-a89a-604b3e979aa8'\n",
    "# Consecutive records between 10 mins but with different kind of material decription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a6fe2bcc-c031-439b-a89a-604b3e979aa8\n",
    "# In a group of duplicate items and in the 2 list there is at least one record 'A' find the best candidate to mask as 'A' insted of 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NST01 into the network\n",
    "#con = mdb.connect('172.16.0.19', 'mercenary', 'Flxi8571', 'Sustayn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NST01 outside the network\n",
    "#con = mdb.connect('52.173.202.38', 'mercenary', 'Flxi8571', 'Sustayn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#update_audited_records(conn, 'A', 'AutoAI', process_time, 'null', '0000b551-ea3d-4483-b030-1bd702fc5e1d')\n",
    "#update_audited_records(conn, 'R', 'AutoAI', process_time, '9'   , '00031864-34e8-4c6d-b60c-900dfcbec1cc')\n",
    "#update_audited_records(conn, 'D', 'AutoAI', process_time, '9'   , '00034406-1233-4340-abd8-c289f6f8bbdd')\n",
    "#update_audited_records(conn, 'C', 'AutoAI', process_time, 'null', '000101fd-4af8-45fb-b6bb-e6a92137aaae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Scenario A\n",
    "select audit_status, audit_userid, audit_date, \n",
    "from baler.device_producor_history\n",
    "where id = '0b30a0bc-9c1e-464f-ae50-2f81a668a423'\n",
    "\n",
    "# Scenario R\n",
    "select audit_status, audit_userid, audit_date, audit_reject_reasonid\n",
    "from baler.device_producor_history\n",
    "where id = '0b30a0bc-9c1e-464f-ae50-2f81a668a423'\n",
    "\n",
    "# Scenario D\n",
    "select audit_status, audit_userid, audit_date, audit_reject_reasonid\n",
    "from baler.device_producor_history\n",
    "where id = '0b30a0bc-9c1e-464f-ae50-2f81a668a423'\n",
    "\n",
    "# Scenario C\n",
    "SELECT  audit_status, audit_userid, audit_date, package_date, create_date, tare_weight, gross_weight\n",
    "from baler.device_producor_history\n",
    "where id = '0b30a0bc-9c1e-464f-ae50-2f81a668a423';\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
